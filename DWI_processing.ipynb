{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from dipy.io import read_bvals_bvecs\n",
    "from dipy.core.gradients import gradient_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_id = \"100206\"\n",
    "subject_path = f\"diffusion_data/{subject_id}/T1w/Diffusion\"\n",
    "dwi_img = nib.load(f'{subject_path}/data.nii.gz')\n",
    "mask_img = nib.load(f'{subject_path}/nodif_brain_mask.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy arrays for processing\n",
    "dwi_data = dwi_img.get_fdata()\n",
    "mask = mask_img.get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DWI data shape: (145, 174, 145, 288)\n",
      "Mask shape: (145, 174, 145)\n"
     ]
    }
   ],
   "source": [
    "print(f\"DWI data shape: {dwi_data.shape}\")  # Should be (X, Y, Z, num_volumes)\n",
    "print(f\"Mask shape: {mask.shape}\")          # Should be (X, Y, Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading gradient information...\n",
      "Number of gradient directions: 288\n",
      "bvals shape: (288,)\n",
      "bvecs shape: (288, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load gradient information (bvals and bvecs)\n",
    "print(\"\\nLoading gradient information...\")\n",
    "bvals, bvecs = read_bvals_bvecs(f'{subject_path}/bvals', \n",
    "                               f'{subject_path}/bvecs')\n",
    "print(f\"Number of gradient directions: {len(bvals)}\")\n",
    "print(f\"bvals shape: {bvals.shape}\")     # Should match number of volumes\n",
    "print(f\"bvecs shape: {bvecs.shape}\")     # Should be (num_volumes, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create gradient table for DIPY\n",
    "gtab = gradient_table(bvals, bvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of B0 volumes: 18\n",
      "B0 data shape: (145, 174, 145, 18)\n",
      "Average B0 shape: (145, 174, 145)\n"
     ]
    }
   ],
   "source": [
    "# Identify and extract B0 (non-diffusion weighted) volumes\n",
    "b0_mask = gtab.b0s_mask\n",
    "b0_data = dwi_data[..., b0_mask]\n",
    "print(f\"\\nNumber of B0 volumes: {np.sum(b0_mask)}\")\n",
    "print(f\"B0 data shape: {b0_data.shape}\")\n",
    "# Average B0 volumes to get a single reference image\n",
    "b0_avg = np.mean(b0_data, axis=-1)\n",
    "print(f\"Average B0 shape: {b0_avg.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of DWI volumes: 270\n",
      "DWI volumes shape: (145, 174, 145, 270)\n"
     ]
    }
   ],
   "source": [
    "# Extract and normalize diffusion weighted volumes\n",
    "dwi_mask = ~b0_mask  # Mask for diffusion weighted volumes\n",
    "dwi_vols = dwi_data[..., dwi_mask]\n",
    "print(f\"\\nNumber of DWI volumes: {np.sum(dwi_mask)}\")\n",
    "print(f\"DWI volumes shape: {dwi_vols.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized DWI shape: (145, 174, 145, 270)\n"
     ]
    }
   ],
   "source": [
    "# Normalize DWI volumes by B0 (avoid division by zero with small epsilon)\n",
    "dwi_norm = dwi_vols / (b0_avg[..., None] + 1e-6)\n",
    "print(f\"Normalized DWI shape: {dwi_norm.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of valid voxels in mask: 936256\n"
     ]
    }
   ],
   "source": [
    "# Find valid voxels using the brain mask\n",
    "valid_idx = np.where(mask > 0)\n",
    "print(f\"\\nNumber of valid voxels in mask: {len(valid_idx[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample random voxels for training\n",
    "n_samples = 50000  # Adjust this number based on your needs\n",
    "sample_idx = np.random.choice(len(valid_idx[0]), \n",
    "                            min(n_samples, len(valid_idx[0])), \n",
    "                            replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features (signal intensities) from sampled voxels\n",
    "features = []\n",
    "for idx in sample_idx:\n",
    "    x, y, z = valid_idx[0][idx], valid_idx[1][idx], valid_idx[2][idx]\n",
    "    features.append(dwi_norm[x, y, z, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(features)\n",
    "gradient_directions = bvecs[dwi_mask]  # Only keep directions for DWI volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final data shapes:\n",
      "Features shape: (50000, 270)\n",
      "Gradient directions shape: (270, 3)\n",
      "\n",
      "Sanity checks:\n",
      "Max normalized value: 474281555.17578125\n",
      "Min normalized value: 0.0\n",
      "Gradient directions magnitude close to 1: True\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFinal data shapes:\")\n",
    "print(f\"Features shape: {features.shape}\")           # Should be (n_samples, n_directions)\n",
    "print(f\"Gradient directions shape: {gradient_directions.shape}\")  # Should be (n_directions, 3)\n",
    "\n",
    "# Basic sanity checks\n",
    "print(\"\\nSanity checks:\")\n",
    "print(f\"Max normalized value: {np.max(features)}\")\n",
    "print(f\"Min normalized value: {np.min(features)}\")\n",
    "print(f\"Gradient directions magnitude close to 1: {np.allclose(np.linalg.norm(gradient_directions, axis=1), 1, atol=1e-3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ground truth data...\n",
      "Ground truth tensors shape: (936256, 6)\n",
      "Valid coordinates shape: (936256, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading ground truth data...\")\n",
    "gt_data = np.load('ground_truth.npz')\n",
    "ground_truth_tensors = gt_data['tensors']\n",
    "valid_coordinates = gt_data['coordinates']\n",
    "print(f\"Ground truth tensors shape: {ground_truth_tensors.shape}\")\n",
    "print(f\"Valid coordinates shape: {valid_coordinates.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating graphs for batch of 32 voxels using 21 directions each\n",
      "\n",
      "First sample edge check:\n",
      "Total edges created: 80\n",
      "Example edges and their angles:\n",
      "Edge 0: 0->19, Angle: 24.71 degrees\n",
      "Edge 1: 1->3, Angle: 24.15 degrees\n",
      "Edge 2: 1->6, Angle: 20.78 degrees\n",
      "Edge 3: 1->8, Angle: 36.96 degrees\n",
      "Edge 4: 1->12, Angle: 37.86 degrees\n",
      "\n",
      "Batch statistics:\n",
      "Number of samples in batch: 32\n",
      "Number of nodes per graph: 21\n",
      "Node feature dimensionality: 4\n",
      "Ground truth tensors: 32\n",
      "\n",
      "First sample in batch:\n",
      "Number of nodes: 21\n",
      "Number of edges: 80\n",
      "Ground truth tensor components: [ 8.39275777e-04 -2.08106019e-05  9.17346774e-04  4.89926518e-05\n",
      " -1.59106882e-06  8.41369929e-04]\n"
     ]
    }
   ],
   "source": [
    "# Number of directions to use for sparse estimation\n",
    "n_directions = 21  # We can adjust this number\n",
    "\n",
    "def create_graph_data(features, gradient_directions, n_sparse_directions, batch_size = 32, threshold_angle = 45):\n",
    "    \"\"\"\n",
    "    Create graph data for a batch of samples, including ground tensor\n",
    "    \"\"\"\n",
    "    voxel_indices = np.random.choice(len(features), size = batch_size, replace = False)\n",
    "    print(f\"Creating graphs for batch of {batch_size} voxels using {n_sparse_directions} directions each\")\n",
    "    \n",
    "    batch_nodes = []\n",
    "    batch_edges = []\n",
    "    batch_tensors = []\n",
    "\n",
    "    for idx in voxel_indices:\n",
    "        # Randomly selected directions\n",
    "        selected_dir_idx = np.random.choice(len(gradient_directions), size=n_sparse_directions, replace=False)\n",
    "\n",
    "        directions = gradient_directions[selected_dir_idx]\n",
    "        signals = features[idx, selected_dir_idx]\n",
    "        \n",
    "        # Create node features: x, y, z, signal\n",
    "        nodes = np.column_stack([directions, signals])\n",
    "\n",
    "        # Create edges acc. to angle\n",
    "        directions_norm = directions / np.linalg.norm(directions, axis=1, keepdims=True)\n",
    "        cos_sim = np.dot(directions_norm, directions_norm.T)\n",
    "        angles = np.arccos(np.clip(cos_sim, -1.0, 1.0)) * 180/np.pi\n",
    "        \n",
    "        src, dst = np.where(angles < threshold_angle)\n",
    "        mask = src != dst\n",
    "        edges = np.column_stack([src[mask], dst[mask]])\n",
    "\n",
    "        batch_nodes.append(nodes)\n",
    "        batch_edges.append(edges)\n",
    "        batch_tensors.append(ground_truth_tensors[idx])\n",
    "\n",
    "        if idx == voxel_indices[0]:\n",
    "            print(\"\\nFirst sample edge check:\")\n",
    "            print(f\"Total edges created: {edges.shape[0]}\")\n",
    "            print(\"Example edges and their angles:\")\n",
    "            for i in range(min(5, len(edges))):\n",
    "                e1, e2 = edges[i]\n",
    "                print(f\"Edge {i}: {e1}->{e2}, Angle: {angles[e1,e2]:.2f} degrees\")\n",
    "        \n",
    "    return batch_nodes, batch_edges, batch_tensors\n",
    "\n",
    "nodes, edges, gt_tensors = create_graph_data(features, gradient_directions, n_directions)\n",
    "# Print info for verification\n",
    "print(\"\\nBatch statistics:\")\n",
    "print(f\"Number of samples in batch: {len(nodes)}\")\n",
    "print(f\"Number of nodes per graph: {nodes[0].shape[0]}\")\n",
    "print(f\"Node feature dimensionality: {nodes[0].shape[1]}\")\n",
    "print(f\"Ground truth tensors: {len(gt_tensors)}\")\n",
    "\n",
    "# Print example for first sample\n",
    "print(\"\\nFirst sample in batch:\")\n",
    "print(f\"Number of nodes: {nodes[0].shape[0]}\")\n",
    "print(f\"Number of edges: {edges[0].shape[0]}\")\n",
    "print(f\"Ground truth tensor components: {gt_tensors[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data, Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionGNN(torch.nn.Module):\n",
    "    def __init__(self, node_features = 4, hidden_dim = 32):\n",
    "        super(DiffusionGNN, self).__init__()\n",
    "    \n",
    "        # Layers\n",
    "        self.conv1 = DiffusionConv(node_features, hidden_dim)\n",
    "        self.conv2 = DiffusionConv(hidden_dim, hidden_dim)\n",
    "\n",
    "        # MLP for tensor prediction\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 6)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, edge_index, batch):\n",
    "        \"\"\"\n",
    "        x: node_features\n",
    "        edge_index = graph conn info [2, num_edges]\n",
    "        batch: batch assignment for nodes\n",
    "        \"\"\"\n",
    "        # pass through gnn layers\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # combine node features for graph\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_dim]\n",
    "\n",
    "        # raw predictions\n",
    "        out = self.mlp(x)\n",
    "\n",
    "        diag = out[:, :3] # Dxx, Dyy, Dzz\n",
    "        offdiag = out[:, 3:] # Dxy, Dyz, Dxz\n",
    "\n",
    "        diag = torch.sigmoid(diag)\n",
    "        offdiag = torch.tanh(offdiag)\n",
    "\n",
    "        return torch.cat([diag, offdiag], dim = 1)\n",
    "\n",
    "\n",
    "\n",
    "class DiffusionConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DiffusionConv, self).__init__(aggr=\"mean\")\n",
    "        \n",
    "        # MLP to process messages\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(2 * in_channels, out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(out_channels, out_channels)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        return self.propogate(edge_index, x=x)\n",
    "    \n",
    "    def message(self, x_i, x_j):\n",
    "        \"\"\"\n",
    "        x_i: features of target nodes\n",
    "        x_j: features of source nodes\n",
    "        Returns: messages to be aggregated\n",
    "        \"\"\"\n",
    "        tmp = torch.cat([x_i, x_j], dim = 1)\n",
    "        return self.mlp(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
